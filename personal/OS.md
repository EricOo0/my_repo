哈工大-李治军老师-操作系统
# 计算机上电到启动的过程发生了什么  （操作系统和硬件）
```
接通电源前，系统CPU 处于实模式，寻址空间为16位，cs（段寄存器）和ip（偏移寄存器）都指向固化在rom中的BIOS程序
接通电源，系统指向BIOS程序，进行硬件的检测和初始化，然后将磁盘0磁道0扇区的代码读入内存（OS的代码），设置cs和ip指向os的bootsect.s代码,控制权交os
bootsect.s引导操作系统，导入setup.s代码到指定位置，setup设置内存等一系列操作，将操作系统代码移动到0地址处，并进入保护模式（32位寻址）
执行system模块的代码，初始化os，操作系统开始执行main函数
--setup.s时候读取的内存参数在这时候初始化时用于设置mmap数组(4k 一页)，指示哪些内存已使用，哪些内存未使用
```

# 操作系统的接口————系统调用  （应用程序和操作系统）
```
操作系统分为用户态和内核态，用户态代码不能访问内核态代码，这是由硬件设定好的：执行代码是会检查DPL（目标特权级） CPL（目前特权级），满足CPL<=DPL才能执行
（用户态可以直接访问内核态是不安全的）
只能通过中断来从用户态进入内核态（INT 0x80），由系统调用实现
用户态代码-->调用system_call函数（比如wirte（））-->system_call设置中断置0x80-->触发软中断，进入内核态-->根据调用号去找对应的中断处理函数，执行对应操作-->返回用户态

```

# CPU管理 1
```
CPU功能：取值执行，从内存中一条条取代码，执行代码。
进程的概念：运行着的程序就是进程
CPU是管理进程的设备，管理CPU实际上就是管理进程，但是IO指令速度远远小于计算指令，单进程执行的化CPU效率很低
因此有了并发的概念：并发--让一个CPU交替执行多个进程，不在等待IO上浪费时间；CPU管理并发的多个进程是CPU管理的关键

进程的切换执行依赖于PCB（process control block），每个进程都有一个PCB表，存放着上下文信息，用于保护现场。进程切换时将cpu运行信息压入PCB，将要切换的进程PCB换到CPU中，完成进程切换
进程的状态：运行态 就绪态 等待/阻塞态
CPU维持三个队列 运行队列 就绪队列 等待队列，队列的头尾指针各自指向对应进程的PCB，用于进程的切换
队列的维持方式取决于调度方式--队列操作+调度+切换！

进程同步：进程之间可能共享一些资源，进程切换可能导致资源更新出错，需要进行同步，常见方法：加锁
linux系统进入main函数后，调用fork创建第一个进程（1号进程），启动shell，后续的所有其他进程都由这个1号进程产生。
```

# CPU管理2
```
进程=资源+指令执行序列
进程的切换需要切换资源，消耗大，因而引入了线程的概念，线程共享进程的资源，切换线程只需要切换指令，消耗小。
线程拥有自己的栈空间，TCB线程控制块，用于线程切换
用户线程：
	只在用户空间，不进入核空间；每个线程都有一个自己的用户栈，TCB。通过Yield函数切换到不同的线程执行；缺点：内核阻塞了的话会切换到其他进程，内核并不知道有多线程
内核线程：
	每个线程有一套用户栈核内核栈
	线程切换的过程：线程运行，陷入到内核栈，保存用户栈的信息，更新TCB，切换到其他线程，出战对应用户栈的信息，跳转到用户态执行另一个线程
## fork创建子进程：
	用户态调用fork系统调用，通过INT0X80陷入内核态，在内核态重新申请了一页内存，子进程拥有了自己的内核栈，但内核栈指向的用户栈仍然时从父进程复制过来的
	即 子进程和父进程拥有同一个用户栈，各自拥有自己的内核栈(后面通过exec修改)
```

# CPU管理3 
```	
	cpu调度，CPU调度要综合折中响应时间和周转时间，
	常见的CPU调度方法：FIFO FCFS（先来先服务） SJF(短作业优先) 时间片轮转ROUND Robin 优先级调度
	单纯的优先级调度会导致低优先级的进程饿死，因此常用动态更新优先级+时间片轮转进行调度，保证了响应时间的同时，优先IO密集型进程
```

# 进程同步
```
	通过信号量实现
	信号量表示还有多少资源，通过PV操作进行加减
	每次进行一次P操作将信号量减一，如果信号量<0，表示没有资源，则进入sleep
	每次进行一次V操作将信号量加一，如果信号量<=0,表示还有进程等待中，则wakeup一个进程。
	通过信号量保证了进程之间的同步
	
	临界区：一次只允许一个进程进入
	mutex是硬件原子指令，不需要用软件保护。用mutex作为信号量来保护其他信号量（用临界区保护信号量，用信号量实现进程同步）
```

# 死锁
```
环路等待 ，资源互斥使用，多个进程互相等待对方持有的资源而造成谁都无法进行下去的情况。
死锁的四个形成条件：1互斥使用，2不可抢占 3 请求和保持（保持当前资源，请求下个资源） 4循环等待
死锁预防：破坏死锁形成的条件 ————一次性申请所有资源、资源申请按序申请；————会造成资源浪费
死锁避免：检测资源请求，造成死锁就拒绝————银行家算法：
死锁检测+恢复：让资源回滚 让出资源
死锁忽略
```

# 内存管理1 （程序分段+内存分页）
```
1、直接使用物理内存会有矛盾（必须使用0地址但不可以使用）
2、使用逻辑地址（基址+偏移=物理地址） ——运行时重定位（编译时重定位，载入时重定位都会造成问题）--基址放在PCB中

3、分段：实际应用中不是将整个程序一起取到内存；（程序由多个部分组成：程序段，数据段，堆，栈等 逻辑地址都从0开始，应该有不同的基址，分别管理）
	各段分别放入内存（段+段内偏移寻址 ——进程段表LDT-放在PCB中）
	
4、内存分区：内存如何分成多个区用于分配个程序？可变分区-- 空闲分区表，已分配分区表，
		分区会带来很多内存碎片，效率不高，需要内存紧缩
5、分页：每个段都分成一页一页的（4k一页）；段号+页号+内存映射mmu（页表）

6、多级页表：对于一个程序（32位），有4M个页表项，多个进程并发的时候，页表占用的空间就很大了；
	1、解决办法：如果将未使用的页表项去掉，使页表不连续，可以节省内存但查找要耗费较大时间
	2、解决办法：使用多级页表：10bit的页目录 10bit的页号，这样内存只用存完整的页目录(一级页表-2^10*4=4K)和有使用的页目录对应的页表（二级页表，也是4K）
				（没有使用的二级页表可以不存放到内存）以此减少空间；每次查找时，先查页目录号，再查对应的页表
	多级页表节省了空间，但每增加一级页表也要增加一次访存
7、快表：当系统是64位或更高时，需要使用更多级的页表，即更多次访存。所以在寄存器中建立了一个快表TLB，块表存放经常访问的页号和对应物理页框的关系。
		 如果TLB命中，则直接去找对应的页框，如果没命中，则继续通过多级页表查找
8、段页结合： 程序希望分段，内存希望分页
			   因此引入虚拟内存的概念。对于一个程序，先在虚拟内存中分配各段的地址，建立段表（每个进程有自己的虚拟内存）；（后续分页对程序是透明的）
			   虚拟内存需要进一步进行分页，建立页表，完成和物理内存的映射关系
			   程序执行的过程中：根据进程的段表（段号+偏移）找到虚拟地址，虚拟地址根据页表找到物理页框
			   MMU负责地址的转换
9、写时复制：fork一个进程时，子进程开辟了自己的虚拟内存，复制了父进程的页表（共用一套页表），先指向父进程页表的指向的内存，但是时只读的，当要写时，才申请内存，更新页表			   
10、内存换入换出：
		页表没有映射的时候，请求换入（缺页中断14号，更新页表）
		内存有限，需要把有的页换出内存（换出算法 -LRU最近最少使用-- 增加引用位+循环队列）
		
```

# 文件管理--一切都是文件
```
1、IO管理
	out:
	CPU给外设的控制器（显卡，磁卡等）的寄存器写命令 ，控制器完成真正的工作，向CPU发出中断
	统一的操作外设的顺序：open、write、read，close--操作系统位用户提供的统一的操作外设
	下层会根据设备选择驱动，进行解释，操作控制器
	inode存放设备信息（PCB有一个filp表，存放的一系列指针（文件描述符？）指向对应外设的inode）
	
	找到外设后，根据设备类型：字符设备和块设备：
		主设备号--> 查到对应的处理函数-驱动
		从设备号--> 和设备有关
	In:
	键盘：中断(21号中断)

2、磁盘管理
	生磁盘：1、磁道（柱面，半径）：控制器寻找磁道；2、选择磁头（高）；3、磁盘的访问单位是扇区，一个扇区512字节；
	上述部门通过磁盘驱动完成，程序只需要发出一个盘块号
	熟磁盘-从文件得到盘块号：FCB文件控制块
		连续存储适合读写但不适合动态增长
		链式存储
		索引 inode--即FCB
	文件系统
	
```


